{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業:\n",
    "嘗試調整參數:  \n",
    "sg:sg=1表示採用skip-gram,sg=0 表示採用cbow  \n",
    "window:能往左往右看幾個字的意思 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec on the two sentences  \n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['I am a hero', 'sentence'], ['She is a teacher', 'sentence']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\AI_course\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "2019-03-12 10:49:27,189 : INFO : collecting all words and their counts\n",
      "2019-03-12 10:49:27,209 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-12 10:49:27,212 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2019-03-12 10:49:27,218 : INFO : Loading a fresh vocabulary\n",
      "2019-03-12 10:49:27,220 : INFO : effective_min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2019-03-12 10:49:27,221 : INFO : effective_min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2019-03-12 10:49:27,222 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2019-03-12 10:49:27,224 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2019-03-12 10:49:27,226 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2019-03-12 10:49:27,227 : INFO : estimated required memory for 3 words and 256 dimensions: 7644 bytes\n",
      "2019-03-12 10:49:27,228 : INFO : resetting layer weights\n",
      "2019-03-12 10:49:27,229 : INFO : training model with 4 workers on 3 vocabulary and 256 features, using sg=1 hs=0 sample=0.001 negative=5 window=3\n",
      "2019-03-12 10:49:27,259 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,260 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,261 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,262 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,295 : INFO : EPOCH - 1 : training on 4 raw words (1 effective words) took 0.0s, 27 effective words/s\n",
      "2019-03-12 10:49:27,330 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,335 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,338 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,341 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,343 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,353 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,354 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,356 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,369 : INFO : EPOCH - 3 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,412 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,414 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,420 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,444 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,446 : INFO : EPOCH - 4 : training on 4 raw words (1 effective words) took 0.0s, 28 effective words/s\n",
      "2019-03-12 10:49:27,474 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,479 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,485 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,494 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,496 : INFO : training on a 20 raw words (2 effective words) took 0.3s, 8 effective words/s\n",
      "2019-03-12 10:49:27,504 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=256, alpha=0.025)\n",
      "similarity (window=3, sg=1): -0.12108129262924194\n"
     ]
    }
   ],
   "source": [
    "# train word2vec on the two sentences  \n",
    "model = word2vec.Word2Vec(sentences, size=256, min_count=1, window=3, workers=4, sg=1)  \n",
    "print(model)\n",
    "print(f\"similarity (window=3, sg=1): {model.wv.similarity('I am a hero','She is a teacher')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-12 10:49:27,567 : INFO : collecting all words and their counts\n",
      "2019-03-12 10:49:27,571 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-12 10:49:27,585 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2019-03-12 10:49:27,592 : INFO : Loading a fresh vocabulary\n",
      "2019-03-12 10:49:27,597 : INFO : effective_min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2019-03-12 10:49:27,607 : INFO : effective_min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2019-03-12 10:49:27,610 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2019-03-12 10:49:27,620 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2019-03-12 10:49:27,626 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2019-03-12 10:49:27,631 : INFO : estimated required memory for 3 words and 256 dimensions: 7644 bytes\n",
      "2019-03-12 10:49:27,639 : INFO : resetting layer weights\n",
      "2019-03-12 10:49:27,641 : INFO : training model with 4 workers on 3 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n",
      "2019-03-12 10:49:27,658 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,669 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,672 : INFO : EPOCH - 1 : training on 4 raw words (1 effective words) took 0.0s, 67 effective words/s\n",
      "2019-03-12 10:49:27,726 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,729 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,737 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,746 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,748 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,750 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,761 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,763 : INFO : EPOCH - 3 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,779 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,781 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,784 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,802 : INFO : EPOCH - 4 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,815 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,818 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,828 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:27,842 : INFO : training on a 20 raw words (1 effective words) took 0.2s, 5 effective words/s\n",
      "2019-03-12 10:49:27,847 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=256, alpha=0.025)\n",
      "similarity (window=3, sg=0): -0.12108129262924194\n"
     ]
    }
   ],
   "source": [
    "# sg=0 表示COBW, sg=1 表示skip-gram\n",
    "model = word2vec.Word2Vec(sentences, size=256, min_count=1, window=3, workers=4, sg=0)  \n",
    "print(model)\n",
    "print(f\"similarity (window=3, sg=0): {model.wv.similarity('I am a hero','She is a teacher')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-12 10:49:27,875 : INFO : collecting all words and their counts\n",
      "2019-03-12 10:49:27,886 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-12 10:49:27,889 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2019-03-12 10:49:27,891 : INFO : Loading a fresh vocabulary\n",
      "2019-03-12 10:49:27,894 : INFO : effective_min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2019-03-12 10:49:27,896 : INFO : effective_min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2019-03-12 10:49:27,899 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2019-03-12 10:49:27,902 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2019-03-12 10:49:27,904 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2019-03-12 10:49:27,907 : INFO : estimated required memory for 3 words and 256 dimensions: 7644 bytes\n",
      "2019-03-12 10:49:27,911 : INFO : resetting layer weights\n",
      "2019-03-12 10:49:27,919 : INFO : training model with 4 workers on 3 vocabulary and 256 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-03-12 10:49:27,936 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,939 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,941 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:27,946 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:27,950 : INFO : EPOCH - 1 : training on 4 raw words (1 effective words) took 0.0s, 65 effective words/s\n",
      "2019-03-12 10:49:27,984 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:27,990 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:27,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,007 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,029 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,036 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,052 : INFO : EPOCH - 3 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,075 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,092 : INFO : EPOCH - 4 : training on 4 raw words (1 effective words) took 0.0s, 56 effective words/s\n",
      "2019-03-12 10:49:28,124 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,127 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,135 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,138 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,140 : INFO : training on a 20 raw words (2 effective words) took 0.2s, 9 effective words/s\n",
      "2019-03-12 10:49:28,147 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=256, alpha=0.025)\n",
      "similarity (window=5, sg=1): -0.12108129262924194\n"
     ]
    }
   ],
   "source": [
    "# train word2vec on the two sentences  \n",
    "model = word2vec.Word2Vec(sentences, size=256, min_count=1, window=5, workers=4, sg=1)  \n",
    "print(model)\n",
    "print(f\"similarity (window=5, sg=1): {model.wv.similarity('I am a hero','She is a teacher')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-12 10:49:28,168 : INFO : collecting all words and their counts\n",
      "2019-03-12 10:49:28,174 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-03-12 10:49:28,176 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2019-03-12 10:49:28,177 : INFO : Loading a fresh vocabulary\n",
      "2019-03-12 10:49:28,181 : INFO : effective_min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2019-03-12 10:49:28,200 : INFO : effective_min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2019-03-12 10:49:28,207 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2019-03-12 10:49:28,210 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2019-03-12 10:49:28,212 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2019-03-12 10:49:28,222 : INFO : estimated required memory for 3 words and 256 dimensions: 7644 bytes\n",
      "2019-03-12 10:49:28,225 : INFO : resetting layer weights\n",
      "2019-03-12 10:49:28,231 : INFO : training model with 4 workers on 3 vocabulary and 256 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-03-12 10:49:28,263 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,267 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,273 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,286 : INFO : EPOCH - 1 : training on 4 raw words (1 effective words) took 0.0s, 38 effective words/s\n",
      "2019-03-12 10:49:28,312 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,313 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,319 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,326 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,343 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,344 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,357 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,361 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,368 : INFO : EPOCH - 3 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,403 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,408 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,410 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,413 : INFO : EPOCH - 4 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,440 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-03-12 10:49:28,441 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-03-12 10:49:28,444 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-03-12 10:49:28,445 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-03-12 10:49:28,447 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2019-03-12 10:49:28,448 : INFO : training on a 20 raw words (1 effective words) took 0.2s, 5 effective words/s\n",
      "2019-03-12 10:49:28,462 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=256, alpha=0.025)\n",
      "similarity (window=5, sg=0): -0.12108129262924194\n"
     ]
    }
   ],
   "source": [
    "# train word2vec on the two sentences  \n",
    "model = word2vec.Word2Vec(sentences, size=256, min_count=1, window=5, workers=4, sg=0)  \n",
    "print(model)\n",
    "print(f\"similarity (window=5, sg=0): {model.wv.similarity('I am a hero','She is a teacher')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
